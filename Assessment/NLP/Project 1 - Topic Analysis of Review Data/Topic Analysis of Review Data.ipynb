{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3f87492",
   "metadata": {},
   "source": [
    "**DESCRIPTION**\n",
    "\n",
    "Help a leading mobile brand understand the voice of the customer by analyzing the reviews of their product on Amazon and the topics that customers are talking about. You will perform topic modeling on specific parts of speech. You’ll finally interpret the emerging topics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6c9475",
   "metadata": {},
   "source": [
    "**Problem Statement:**\n",
    "    \n",
    "A popular mobile phone brand, Lenovo has launched their budget smartphone in the Indian market. The client wants to understand the VOC (voice of the customer) on the product. This will be useful to not just evaluate the current product, but to also get some direction for developing the product pipeline. The client is particularly interested in the different aspects that customers care about. Product reviews by customers on a leading e-commerce site should provide a good view.\n",
    "\n",
    "**Domain:** Amazon reviews for a leading phone brand\n",
    "    \n",
    "**Analysis to be done:** POS tagging, topic modeling using LDA, and topic interpretation\n",
    "    \n",
    "**Content:**\n",
    "    \n",
    "**Dataset:** ‘K8 Reviews v0.2.csv’\n",
    "    \n",
    "**Columns:**\n",
    "    \n",
    "Sentiment: The sentiment against the review (4,5 star reviews are positive, 1,2 are negative)\n",
    "    \n",
    "Reviews: The main text of the review\n",
    "    \n",
    "**Steps to perform:**\n",
    "    \n",
    "Discover the topics in the reviews and present it to business in a consumable format. Employ techniques in syntactic processing and topic modeling.\n",
    "Perform specific cleanup, POS tagging, and restricting to relevant POS tags, then, perform topic modeling using LDA. Finally, give business-friendly names to the topics and make a table for business.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cf13e3",
   "metadata": {},
   "source": [
    "# Tasks: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8b373c",
   "metadata": {},
   "source": [
    "### 1.\tRead the .csv file using Pandas. Take a look at the top few records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a27e7fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01eec4a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Good but need updates and improvements</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Worst mobile i have bought ever, Battery is dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>when I will get my 10% cash back.... its alrea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>The worst phone everThey have changed the last...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                             review\n",
       "0          1             Good but need updates and improvements\n",
       "1          0  Worst mobile i have bought ever, Battery is dr...\n",
       "2          1  when I will get my 10% cash back.... its alrea...\n",
       "3          1                                               Good\n",
       "4          0  The worst phone everThey have changed the last..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = pd.read_csv(r'D:\\1. AIML, projects\\6. PG AI - Natural Language Processing and Speech Recognition\\0. Assessments\\Project 1 - Topic Analysis of Review Data\\K8 Reviews v0.2.csv')\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e268633e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.sentiment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2790dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>Good but need updates and improvements</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>Worst mobile i have bought ever, Battery is dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>when I will get my 10% cash back.... its alrea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>The worst phone everThey have changed the last...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                             review\n",
       "0  positive             Good but need updates and improvements\n",
       "1  negative  Worst mobile i have bought ever, Battery is dr...\n",
       "2  positive  when I will get my 10% cash back.... its alrea...\n",
       "3  positive                                               Good\n",
       "4  negative  The worst phone everThey have changed the last..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.sentiment.replace({0:'negative', 1:'positive'}, inplace=True)\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8120c66",
   "metadata": {},
   "source": [
    "## 2.\tNormalize casings for the review text and extract the text into a list for easier manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08df334f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good but need updates and improvements',\n",
       " \"worst mobile i have bought ever, battery is draining like hell, backup is only 6 to 7 hours with internet uses, even if i put mobile idle its getting discharged.this is biggest lie from amazon & lenove which is not at all expected, they are making full by saying that battery is 4000mah & booster charger is fake, it takes at least 4 to 5 hours to be fully charged.don't know how lenovo will survive by making full of us.please don;t go for this else you will regret like me.\",\n",
       " 'when i will get my 10% cash back.... its already 15 january..',\n",
       " 'good',\n",
       " 'the worst phone everthey have changed the last phone but the problem is still same and the amazon is not returning the phone .highly disappointing of amazon',\n",
       " \"only i'm telling don't buyi'm totally disappointedpoor batterypoor camerawaste of money\",\n",
       " 'phone is awesome. but while charging, it heats up allot..really a genuine reason to hate lenovo k8 note',\n",
       " 'the battery level has worn down']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_reviews = []\n",
    "for rev in reviews['review']:\n",
    "    normalized_reviews.append(rev.lower())\n",
    "    \n",
    "normalized_reviews[0:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28b4e49",
   "metadata": {},
   "source": [
    "## 3.\tTokenize the reviews using NLTKs word_tokenize function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bbbe06ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['good', 'but', 'need', 'updates', 'and', 'improvements'], ['worst', 'mobile', 'i', 'have', 'bought', 'ever', ',', 'battery', 'is', 'draining', 'like', 'hell', ',', 'backup', 'is', 'only', '6', 'to', '7', 'hours', 'with', 'internet', 'uses', ',', 'even', 'if', 'i', 'put', 'mobile', 'idle', 'its', 'getting', 'discharged.this', 'is', 'biggest', 'lie', 'from', 'amazon', '&', 'lenove', 'which', 'is', 'not', 'at', 'all', 'expected', ',', 'they', 'are', 'making', 'full', 'by', 'saying', 'that', 'battery', 'is', '4000mah', '&', 'booster', 'charger', 'is', 'fake', ',', 'it', 'takes', 'at', 'least', '4', 'to', '5', 'hours', 'to', 'be', 'fully', 'charged.do', \"n't\", 'know', 'how', 'lenovo', 'will', 'survive', 'by', 'making', 'full', 'of', 'us.please', 'don', ';', 't', 'go', 'for', 'this', 'else', 'you', 'will', 'regret', 'like', 'me', '.'], ['when', 'i', 'will', 'get', 'my', '10', '%', 'cash', 'back', '....', 'its', 'already', '15', 'january', '..'], ['good'], ['the', 'worst', 'phone', 'everthey', 'have', 'changed', 'the', 'last', 'phone', 'but', 'the', 'problem', 'is', 'still', 'same', 'and', 'the', 'amazon', 'is', 'not', 'returning', 'the', 'phone', '.highly', 'disappointing', 'of', 'amazon']]\n"
     ]
    }
   ],
   "source": [
    "reviews_token = [word_tokenize(token) for token in normalized_reviews]\n",
    "print(reviews_token[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6eb6a0a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14675"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba9526d",
   "metadata": {},
   "source": [
    "## 4.\tPerform parts-of-speech tagging on each sentence using the NLTK POS tagger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "aa85d7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('good', 'JJ'), ('but', 'CC'), ('need', 'VBP'), ('updates', 'NNS'), ('and', 'CC'), ('improvements', 'NNS')], [('worst', 'JJS'), ('mobile', 'NN'), ('i', 'NN'), ('have', 'VBP'), ('bought', 'VBN'), ('ever', 'RB'), (',', ','), ('battery', 'NN'), ('is', 'VBZ'), ('draining', 'VBG'), ('like', 'IN'), ('hell', 'NN'), (',', ','), ('backup', 'NN'), ('is', 'VBZ'), ('only', 'RB'), ('6', 'CD'), ('to', 'TO'), ('7', 'CD'), ('hours', 'NNS'), ('with', 'IN'), ('internet', 'JJ'), ('uses', 'NNS'), (',', ','), ('even', 'RB'), ('if', 'IN'), ('i', 'JJ'), ('put', 'VBP'), ('mobile', 'JJ'), ('idle', 'NN'), ('its', 'PRP$'), ('getting', 'VBG'), ('discharged.this', 'NN'), ('is', 'VBZ'), ('biggest', 'JJS'), ('lie', 'NN'), ('from', 'IN'), ('amazon', 'NN'), ('&', 'CC'), ('lenove', 'NN'), ('which', 'WDT'), ('is', 'VBZ'), ('not', 'RB'), ('at', 'IN'), ('all', 'DT'), ('expected', 'VBN'), (',', ','), ('they', 'PRP'), ('are', 'VBP'), ('making', 'VBG'), ('full', 'JJ'), ('by', 'IN'), ('saying', 'VBG'), ('that', 'DT'), ('battery', 'NN'), ('is', 'VBZ'), ('4000mah', 'CD'), ('&', 'CC'), ('booster', 'JJR'), ('charger', 'NN'), ('is', 'VBZ'), ('fake', 'JJ'), (',', ','), ('it', 'PRP'), ('takes', 'VBZ'), ('at', 'IN'), ('least', 'JJS'), ('4', 'CD'), ('to', 'TO'), ('5', 'CD'), ('hours', 'NNS'), ('to', 'TO'), ('be', 'VB'), ('fully', 'RB'), ('charged.do', 'VBP'), (\"n't\", 'RB'), ('know', 'VB'), ('how', 'WRB'), ('lenovo', 'JJ'), ('will', 'MD'), ('survive', 'VB'), ('by', 'IN'), ('making', 'VBG'), ('full', 'JJ'), ('of', 'IN'), ('us.please', 'JJ'), ('don', 'NN'), (';', ':'), ('t', 'CC'), ('go', 'VB'), ('for', 'IN'), ('this', 'DT'), ('else', 'JJ'), ('you', 'PRP'), ('will', 'MD'), ('regret', 'VB'), ('like', 'IN'), ('me', 'PRP'), ('.', '.')], [('when', 'WRB'), ('i', 'NN'), ('will', 'MD'), ('get', 'VB'), ('my', 'PRP$'), ('10', 'CD'), ('%', 'NN'), ('cash', 'NN'), ('back', 'RB'), ('....', 'VBZ'), ('its', 'PRP$'), ('already', 'RB'), ('15', 'CD'), ('january', 'JJ'), ('..', 'NN')], [('good', 'JJ')], [('the', 'DT'), ('worst', 'JJS'), ('phone', 'NN'), ('everthey', 'NN'), ('have', 'VBP'), ('changed', 'VBN'), ('the', 'DT'), ('last', 'JJ'), ('phone', 'NN'), ('but', 'CC'), ('the', 'DT'), ('problem', 'NN'), ('is', 'VBZ'), ('still', 'RB'), ('same', 'JJ'), ('and', 'CC'), ('the', 'DT'), ('amazon', 'NN'), ('is', 'VBZ'), ('not', 'RB'), ('returning', 'VBG'), ('the', 'DT'), ('phone', 'NN'), ('.highly', 'RB'), ('disappointing', 'JJ'), ('of', 'IN'), ('amazon', 'NN')]]\n"
     ]
    }
   ],
   "source": [
    "reviews_pos = [nltk.pos_tag(word) for word in reviews_token]\n",
    "print(reviews_pos[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f1780835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14675"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11806f1e",
   "metadata": {},
   "source": [
    "## 5.\tFor the topic model, we should  want to include only nouns.\n",
    "\n",
    "    1.\tFind out all the POS tags that correspond to nouns.\n",
    "    \n",
    "    2.\tLimit the data to only terms with these tags.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c95a0347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hell\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "93229"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_noun = []\n",
    "\n",
    "for sent in reviews_pos:\n",
    "    noun_words = [term for term, pos in sent if pos.startswith('NN')]\n",
    "    reviews_noun.extend(noun_words)\n",
    "    \n",
    "print(reviews_noun[5])    \n",
    "\n",
    "len(reviews_noun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c2576516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['thing', 'options', 'wrost', 'phone', 'charger', 'damage', 'months', 'item', 'battery', 'life', 'i', 'battery', 'problem', 'motherboard', 'problem', 'months', 'mobile', 'life', 'phone', 'slim', 'battry', 'backup', 'screen', 'headset', 'time', 'i', 'product', 'prize', 'range', 'specification', 'comparison', 'mobile', 'range', 'i', 'phone', 'seal', 'i', 'credit', 'card', 'i', '..', '..', 'deal', 'amazon', '..', 'battery', '..', 'solutions', 'battery', 'life']\n"
     ]
    }
   ],
   "source": [
    "print(reviews_noun[50:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9af4ef",
   "metadata": {},
   "source": [
    "## 6.\tLemmatize. \n",
    "\n",
    "1.\tDifferent forms of the terms need to be treated as one.\n",
    "\n",
    "2.\tNo need to provide POS tag to lemmatizer for now.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3e9928bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "import gensim\n",
    "\n",
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "# Tokenize and lemmatize\n",
    "def preprocess(text):\n",
    "    result=[]\n",
    "    for token in gensim.utils.simple_preprocess(text) :\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "            \n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a6b320ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['good', 'need', 'updat', 'improv'], ['worst', 'mobil', 'buy', 'batteri', 'drain', 'like', 'hell', 'backup', 'hour', 'internet', 'use', 'mobil', 'idl', 'get', 'discharg', 'biggest', 'amazon', 'lenov', 'expect', 'make', 'say', 'batteri', 'booster', 'charger', 'fake', 'take', 'hour', 'fulli', 'charg', 'know', 'lenovo', 'surviv', 'make', 'regret', 'like']]\n"
     ]
    }
   ],
   "source": [
    "processed_docs = []\n",
    "\n",
    "for doc in normalized_reviews:\n",
    "    processed_docs.append(preprocess(doc))\n",
    "\n",
    "print(processed_docs[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d958285d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c9e3fd8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 good\n",
      "1 improv\n",
      "2 need\n",
      "3 updat\n",
      "4 amazon\n",
      "5 backup\n",
      "6 batteri\n",
      "7 biggest\n",
      "8 booster\n",
      "9 buy\n",
      "10 charg\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c15d89dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=15, no_above=0.1, keep_n= 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f72613e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 53 (\"item\") appears 1 time.\n",
      "Word 54 (\"life\") appears 1 time.\n",
      "Word 55 (\"poor\") appears 1 time.\n",
      "Word 56 (\"purchas\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "\n",
    "document_num = 12\n",
    "bow_doc_x = bow_corpus[document_num]\n",
    "\n",
    "for i in range(len(bow_doc_x)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_x[i][0], \n",
    "                                                     dictionary[bow_doc_x[i][0]], \n",
    "                                                     bow_doc_x[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df332dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dec0669e",
   "metadata": {},
   "source": [
    "## 7.\tRemove stopwords and punctuation (if there are any). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "648fec90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d1f9f3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "stop_punc = list(punctuation)\n",
    "stop_final = stop_words+stop_punc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "928bce7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stop_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "88a82591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93229"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews_noun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a7123c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_noun_clean = [term.lower() for term in reviews_noun if term.lower() not in stop_final]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e90ddfc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89324"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews_noun_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1c6da121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['charger',\n",
       " 'hours',\n",
       " 'cash',\n",
       " '..',\n",
       " 'phone',\n",
       " 'everthey',\n",
       " 'phone',\n",
       " 'problem',\n",
       " 'amazon',\n",
       " 'phone',\n",
       " 'amazon',\n",
       " 'camerawaste',\n",
       " 'money',\n",
       " 'phone',\n",
       " 'allot',\n",
       " '..',\n",
       " 'reason',\n",
       " 'k8',\n",
       " 'battery',\n",
       " 'level',\n",
       " 'problems',\n",
       " 'phone',\n",
       " 'hanging',\n",
       " 'problems',\n",
       " 'note',\n",
       " 'station',\n",
       " 'ahmedabad',\n",
       " 'years',\n",
       " 'phone',\n",
       " 'lenovo',\n",
       " 'lot',\n",
       " 'glitches',\n",
       " 'thing',\n",
       " 'options',\n",
       " 'wrost',\n",
       " 'phone',\n",
       " 'charger',\n",
       " 'damage',\n",
       " 'months',\n",
       " 'item',\n",
       " 'battery',\n",
       " 'life',\n",
       " 'battery',\n",
       " 'problem']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_noun_clean[14:58]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66bbd26",
   "metadata": {},
   "source": [
    "## 8.\tCreate a topic model using LDA on the cleaned up data with 12 topics.\n",
    "1.\tPrint out the top terms for each topic.\n",
    "2.\tWhat is the coherence of the model with the c_v metric?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "65b5b139",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=12, id2word=dictionary, \n",
    "                                      passes=10,  workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "32871e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.091*\"amazon\" + 0.048*\"servic\" + 0.047*\"return\" + 0.036*\"replac\" + 0.027*\"issu\" + 0.021*\"time\" + 0.021*\"custom\" + 0.021*\"day\" + 0.019*\"deliveri\" + 0.018*\"want\"\n",
      "\n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.056*\"expect\" + 0.056*\"game\" + 0.048*\"amaz\" + 0.044*\"superb\" + 0.034*\"play\" + 0.031*\"handset\" + 0.029*\"perfect\" + 0.027*\"high\" + 0.025*\"smooth\" + 0.023*\"great\"\n",
      "\n",
      "\n",
      "Topic: 2 \n",
      "Words: 0.136*\"problem\" + 0.073*\"issu\" + 0.067*\"worst\" + 0.066*\"network\" + 0.039*\"drain\" + 0.032*\"hang\" + 0.025*\"support\" + 0.024*\"signal\" + 0.020*\"volt\" + 0.020*\"automat\"\n",
      "\n",
      "\n",
      "Topic: 3 \n",
      "Words: 0.123*\"note\" + 0.045*\"better\" + 0.038*\"featur\" + 0.026*\"glass\" + 0.020*\"redmi\" + 0.020*\"screen\" + 0.020*\"compar\" + 0.017*\"qualiti\" + 0.016*\"gorilla\" + 0.016*\"like\"\n",
      "\n",
      "\n",
      "Topic: 4 \n",
      "Words: 0.064*\"updat\" + 0.034*\"issu\" + 0.034*\"devic\" + 0.021*\"review\" + 0.019*\"month\" + 0.019*\"android\" + 0.018*\"softwar\" + 0.018*\"bluetooth\" + 0.017*\"problem\" + 0.015*\"like\"\n",
      "\n",
      "\n",
      "Topic: 5 \n",
      "Words: 0.049*\"screen\" + 0.034*\"receiv\" + 0.028*\"option\" + 0.024*\"cast\" + 0.021*\"proper\" + 0.019*\"record\" + 0.017*\"contact\" + 0.017*\"time\" + 0.017*\"purchas\" + 0.015*\"worst\"\n",
      "\n",
      "\n",
      "Topic: 6 \n",
      "Words: 0.034*\"mode\" + 0.027*\"depth\" + 0.020*\"dolbi\" + 0.019*\"photo\" + 0.019*\"like\" + 0.018*\"light\" + 0.016*\"dual\" + 0.015*\"screen\" + 0.014*\"video\" + 0.014*\"music\"\n",
      "\n",
      "\n",
      "Topic: 7 \n",
      "Words: 0.127*\"price\" + 0.125*\"best\" + 0.102*\"awesom\" + 0.053*\"rang\" + 0.038*\"love\" + 0.032*\"featur\" + 0.031*\"great\" + 0.030*\"perform\" + 0.023*\"qualiti\" + 0.019*\"smartphon\"\n",
      "\n",
      "\n",
      "Topic: 8 \n",
      "Words: 0.188*\"charg\" + 0.053*\"hour\" + 0.049*\"charger\" + 0.047*\"fast\" + 0.041*\"get\" + 0.041*\"turbo\" + 0.040*\"take\" + 0.038*\"drain\" + 0.036*\"time\" + 0.018*\"issu\"\n",
      "\n",
      "\n",
      "Topic: 9 \n",
      "Words: 0.098*\"perform\" + 0.056*\"qualiti\" + 0.044*\"averag\" + 0.041*\"dual\" + 0.041*\"super\" + 0.041*\"display\" + 0.034*\"speaker\" + 0.032*\"poor\" + 0.031*\"sound\" + 0.028*\"like\"\n",
      "\n",
      "\n",
      "Topic: 10 \n",
      "Words: 0.157*\"money\" + 0.107*\"excel\" + 0.096*\"wast\" + 0.074*\"worth\" + 0.059*\"valu\" + 0.057*\"great\" + 0.025*\"total\" + 0.018*\"worst\" + 0.018*\"buy\" + 0.016*\"featur\"\n",
      "\n",
      "\n",
      "Topic: 11 \n",
      "Words: 0.337*\"nice\" + 0.124*\"qualiti\" + 0.096*\"poor\" + 0.066*\"backup\" + 0.050*\"satisfi\" + 0.026*\"look\" + 0.022*\"process\" + 0.015*\"damag\" + 0.014*\"featur\" + 0.013*\"headphon\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e1b12f",
   "metadata": {},
   "source": [
    "## 9.\tAnalyze the topics through the business lens.\n",
    "1.\tDetermine which of the topics can be combined.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874fa53b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da46a91b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8ca86e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48342adb",
   "metadata": {},
   "source": [
    "## 10.\tCreate topic model using LDA with what you think is the optimal number of topics\n",
    "1.\tWhat is the coherence of the model?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534501b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dad554",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff9f3d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a0513e3",
   "metadata": {},
   "source": [
    "## 11.\tThe business should  be able to interpret the topics.\n",
    "1.\tName each of the identified topics.\n",
    "2.\tCreate a table with the topic name and the top 10 terms in each to present to the  business.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3720abde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
