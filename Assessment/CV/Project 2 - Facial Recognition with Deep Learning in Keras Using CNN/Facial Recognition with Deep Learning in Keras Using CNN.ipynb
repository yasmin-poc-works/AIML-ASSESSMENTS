{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f833e758",
   "metadata": {},
   "source": [
    "# Perform Facial Recognition with Deep Learning in Keras Using CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0b4c58",
   "metadata": {},
   "source": [
    "DESCRIPTION\n",
    "\n",
    "Problem Statement:\n",
    "Facial recognition is a biometric alternative that measures unique characteristics of a human\n",
    "face. Applications available today include flight check in, tagging friends and family members in\n",
    "photos, and “tailored” advertising. You are a computer vision engineer who needs to develop a\n",
    "face recognition programme with deep convolutional neural networks.\n",
    "Objective: Use a deep convolutional neural network to perform facial recognition using Keras.\n",
    "Dataset Details:\n",
    "ORL face database composed of 400 images of size 112 x 92. There are 40 people, 10 images\n",
    "per person. The images were taken at different times, lighting and facial expressions. The faces\n",
    "are in an upright position in frontal view, with a slight left-right rotation.\n",
    "Link to the Dataset: https://www.dropbox.com/s/i7uzp5yxk7wruva/ORL_faces.npz?dl=0\n",
    "Prerequisites:\n",
    "Keras\n",
    "Scikit Learn\n",
    "Steps to be followed:\n",
    "1. Input the required libraries\n",
    "2. Load the dataset after loading the dataset, you have to normalize every image.\n",
    "3. Split the dataset\n",
    "4. Transform the images to equal sizes to feed in CNN\n",
    "5. Build a CNN model that has 3 main layers:\n",
    "\n",
    "i. Convolutional Layer\n",
    "ii. Pooling Layer\n",
    "iii. Fully Connected Layer\n",
    "\n",
    "6. Train the model\n",
    "7. Plot the result\n",
    "8. Iterate the model until the accuracy is above 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93229442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/site-packages (1.18.5)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7078466e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42230c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = np.load('trainX.npy', allow_pickle='TRUE')\n",
    "trainY = np.load('trainY.npy', allow_pickle='TRUE')\n",
    "testX = np.load('testX.npy', allow_pickle='TRUE')\n",
    "testY = np.load('testY.npy', allow_pickle='TRUE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca58a7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 10304)\n",
      "(240,)\n",
      "(160, 10304)\n",
      "(160,)\n"
     ]
    }
   ],
   "source": [
    "print(trainX.shape)\n",
    "print(trainY.shape)\n",
    "print(testX.shape)\n",
    "print(testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e484d091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20855369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 19)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY.min(),trainY.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bfae3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have 20 people data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbcfa09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY = tf.keras.utils.to_categorical(trainY, num_classes=20)\n",
    "testY = tf.keras.utils.to_categorical(testY, num_classes=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "940df879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 20)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54cfa518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no of channels =1,h,w, reshape for the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "573017f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = trainX.reshape(240,112,92,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afd59b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "testX = testX.reshape(160,112,92,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47cc8f2",
   "metadata": {},
   "source": [
    "# view the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "934d0352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in /usr/local/lib/python3.7/site-packages (8.2.0)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd1e5f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=92x112 at 0x7F01C38CC250>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.preprocessing.image.array_to_img(trainX[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "430b60d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=92x112 at 0x7F01C58A6890>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.preprocessing.image.array_to_img(trainX[20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dfb82e",
   "metadata": {},
   "source": [
    "# build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "277a8463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-11-28 16:23:05.677 tensorflow-2-3-gpu-py-ml-t3-medium-e8c155733600f57acc66941bd944:25 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2021-11-28 16:23:05.718 tensorflow-2-3-gpu-py-ml-t3-medium-e8c155733600f57acc66941bd944:25 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Reshape((112,92,1), input_shape=(112,92,1)))\n",
    "#normalize the inputs\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Conv2D(32, #No of filters\n",
    "                                 kernel_size=(3,3),\n",
    "                                 activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2)))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Conv2D(64, kernel_size=(3,3),activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2)))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Conv2D(128, kernel_size=(3,3),activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2)))\n",
    "model.add(tf.keras.layers.Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0111d447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the extracted features in a single dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13544279",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(20, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0a84ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set optimizer and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5839a6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (None, 112, 92, 1)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 112, 92, 1)        4         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 110, 90, 32)       320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 55, 45, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 55, 45, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 53, 43, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 26, 21, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 26, 21, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 19, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 9, 128)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 12, 9, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 13824)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 20)                276500    \n",
      "=================================================================\n",
      "Total params: 369,176\n",
      "Trainable params: 369,174\n",
      "Non-trainable params: 2\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f108859c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "             loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32003944",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e23c5171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "15/15 [==============================] - 4s 256ms/step - loss: 3.2759 - accuracy: 0.0250 - val_loss: 2.9955 - val_accuracy: 0.0500\n",
      "Epoch 2/30\n",
      "15/15 [==============================] - 4s 243ms/step - loss: 2.7798 - accuracy: 0.1458 - val_loss: 2.9831 - val_accuracy: 0.0500\n",
      "Epoch 3/30\n",
      "15/15 [==============================] - 4s 236ms/step - loss: 1.5034 - accuracy: 0.5625 - val_loss: 3.2615 - val_accuracy: 0.0500\n",
      "Epoch 4/30\n",
      "15/15 [==============================] - 4s 234ms/step - loss: 0.4920 - accuracy: 0.8542 - val_loss: 7.2672 - val_accuracy: 0.0500\n",
      "Epoch 5/30\n",
      "15/15 [==============================] - 3s 226ms/step - loss: 0.2513 - accuracy: 0.9000 - val_loss: 7.9652 - val_accuracy: 0.0500\n",
      "Epoch 6/30\n",
      "15/15 [==============================] - 4s 244ms/step - loss: 0.1984 - accuracy: 0.9542 - val_loss: 3.9822 - val_accuracy: 0.1000\n",
      "Epoch 7/30\n",
      "15/15 [==============================] - 4s 236ms/step - loss: 0.1018 - accuracy: 0.9667 - val_loss: 1.9685 - val_accuracy: 0.3750\n",
      "Epoch 8/30\n",
      "15/15 [==============================] - 4s 241ms/step - loss: 0.0676 - accuracy: 0.9750 - val_loss: 2.7273 - val_accuracy: 0.3812\n",
      "Epoch 9/30\n",
      "15/15 [==============================] - 3s 227ms/step - loss: 0.0518 - accuracy: 0.9792 - val_loss: 1.6196 - val_accuracy: 0.5813\n",
      "Epoch 10/30\n",
      "15/15 [==============================] - 4s 240ms/step - loss: 0.0392 - accuracy: 0.9875 - val_loss: 1.5520 - val_accuracy: 0.5875\n",
      "Epoch 11/30\n",
      "15/15 [==============================] - 4s 242ms/step - loss: 0.0232 - accuracy: 0.9917 - val_loss: 0.5362 - val_accuracy: 0.8375\n",
      "Epoch 12/30\n",
      "15/15 [==============================] - 4s 236ms/step - loss: 0.0779 - accuracy: 0.9708 - val_loss: 0.5888 - val_accuracy: 0.8250\n",
      "Epoch 13/30\n",
      "15/15 [==============================] - 4s 233ms/step - loss: 0.0668 - accuracy: 0.9833 - val_loss: 0.5642 - val_accuracy: 0.8313\n",
      "Epoch 14/30\n",
      "15/15 [==============================] - 3s 227ms/step - loss: 0.0522 - accuracy: 0.9875 - val_loss: 0.3950 - val_accuracy: 0.8875\n",
      "Epoch 15/30\n",
      "15/15 [==============================] - 4s 259ms/step - loss: 0.0368 - accuracy: 0.9917 - val_loss: 0.4680 - val_accuracy: 0.8375\n",
      "Epoch 16/30\n",
      "15/15 [==============================] - 3s 229ms/step - loss: 0.0197 - accuracy: 0.9917 - val_loss: 0.2660 - val_accuracy: 0.9438\n",
      "Epoch 17/30\n",
      "15/15 [==============================] - 3s 229ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.3029 - val_accuracy: 0.9500\n",
      "Epoch 18/30\n",
      "15/15 [==============================] - 3s 229ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.2853 - val_accuracy: 0.9625\n",
      "Epoch 19/30\n",
      "15/15 [==============================] - 3s 227ms/step - loss: 0.0138 - accuracy: 0.9958 - val_loss: 0.2767 - val_accuracy: 0.9625\n",
      "Epoch 20/30\n",
      "15/15 [==============================] - 4s 239ms/step - loss: 0.0299 - accuracy: 0.9958 - val_loss: 0.1935 - val_accuracy: 0.9625\n",
      "Epoch 21/30\n",
      "15/15 [==============================] - 4s 234ms/step - loss: 0.0092 - accuracy: 0.9958 - val_loss: 0.1260 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "15/15 [==============================] - 4s 234ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1329 - val_accuracy: 0.9750\n",
      "Epoch 23/30\n",
      "15/15 [==============================] - 4s 240ms/step - loss: 9.6449e-04 - accuracy: 1.0000 - val_loss: 0.1278 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "15/15 [==============================] - 4s 255ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.1837 - val_accuracy: 0.9563\n",
      "Epoch 25/30\n",
      "15/15 [==============================] - 4s 235ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.1670 - val_accuracy: 0.9563\n",
      "Epoch 26/30\n",
      "15/15 [==============================] - 4s 236ms/step - loss: 9.1173e-04 - accuracy: 1.0000 - val_loss: 0.1738 - val_accuracy: 0.9625\n",
      "Epoch 27/30\n",
      "15/15 [==============================] - 4s 238ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2213 - val_accuracy: 0.9563\n",
      "Epoch 28/30\n",
      "15/15 [==============================] - 4s 236ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.2037 - val_accuracy: 0.9563\n",
      "Epoch 29/30\n",
      "15/15 [==============================] - 4s 236ms/step - loss: 4.5582e-04 - accuracy: 1.0000 - val_loss: 0.1891 - val_accuracy: 0.9625\n",
      "Epoch 30/30\n",
      "15/15 [==============================] - 3s 232ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1823 - val_accuracy: 0.9625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f01a00f8650>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX, trainY, validation_data=(testX, testY), epochs=30, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de90c676",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Lets use Transfer learning using ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bbbc0d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data to have 3 channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d2dcc13a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 10304)\n",
      "(240,)\n",
      "(160, 10304)\n",
      "(160,)\n"
     ]
    }
   ],
   "source": [
    "trainX = np.load(\"trainX.npy\", allow_pickle='TRUE')\n",
    "trainY = np.load(\"trainY.npy\", allow_pickle='TRUE')\n",
    "testX = np.load(\"testX.npy\", allow_pickle='TRUE')\n",
    "testY = np.load(\"testY.npy\", allow_pickle='TRUE')\n",
    "print(trainX.shape)\n",
    "print(trainY.shape)\n",
    "print(testX.shape)\n",
    "print(testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a6c3951",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY = tf.keras.utils.to_categorical(trainY, num_classes=20)\n",
    "testY = tf.keras.utils.to_categorical(testY, num_classes=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "413d90b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX= trainX.reshape(240,112,92)\n",
    "testX = testX.reshape(160,112,92)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4c0160dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = np.repeat(trainX[...,np.newaxis],3,-1)\n",
    "testX = np.repeat(testX[...,np.newaxis],3,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d83e9aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 112, 92, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24d5a81",
   "metadata": {},
   "source": [
    "# Create resnet model and download pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c5b26732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.applications.resnet50.ResNet50(include_top=False, #we will make our own FC layer\n",
    "                                                input_shape=(112,92,3),\n",
    "                                                weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2b0b660b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the base layers to not trainable and we will add our own layers\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "13f8665f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv5_block3_out/Relu:0' shape=(None, 4, 3, 2048) dtype=float32>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae937cb",
   "metadata": {},
   "source": [
    "# Add FC layer for our classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2ee11f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#lets get the output tensor\n",
    "x = model.output\n",
    "#Flatten the output in single dim\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "#Add one intermediate dense layer\n",
    "x = tf.keras.layers.Dense(200, activation='relu')(x)\n",
    "#Lets the add the final classification layer(20 modes)\n",
    "prediction = tf.keras.layers.Dense(20, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27da25db",
   "metadata": {},
   "source": [
    "# Build the final model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "df73a78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = tf.keras.models.Model(inputs=model.input,\n",
    "                                    outputs=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ad819883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 112, 92, 3)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 118, 98, 3)   0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 56, 46, 64)   9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 56, 46, 64)   256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 56, 46, 64)   0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 58, 48, 64)   0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 28, 23, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 28, 23, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 28, 23, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 28, 23, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 28, 23, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 28, 23, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 28, 23, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 28, 23, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 28, 23, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 28, 23, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 28, 23, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 28, 23, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 28, 23, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 28, 23, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 28, 23, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 28, 23, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 28, 23, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 28, 23, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 28, 23, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 28, 23, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 28, 23, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 28, 23, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 28, 23, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 28, 23, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 28, 23, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 28, 23, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 28, 23, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 28, 23, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 28, 23, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 28, 23, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 28, 23, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 28, 23, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 28, 23, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 14, 12, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 14, 12, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 14, 12, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 14, 12, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 14, 12, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 14, 12, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 14, 12, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 14, 12, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 14, 12, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 14, 12, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 14, 12, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 14, 12, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 14, 12, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 14, 12, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 14, 12, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 14, 12, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 14, 12, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 14, 12, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 14, 12, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 14, 12, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 14, 12, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 14, 12, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 14, 12, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 14, 12, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 14, 12, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 14, 12, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 14, 12, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 14, 12, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 14, 12, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 14, 12, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 14, 12, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 14, 12, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 14, 12, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 14, 12, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 14, 12, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 14, 12, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 14, 12, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 14, 12, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 14, 12, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 14, 12, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 14, 12, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 14, 12, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 7, 6, 256)    131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 7, 6, 256)    1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 7, 6, 256)    0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 7, 6, 256)    590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 7, 6, 256)    1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 7, 6, 256)    0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 7, 6, 1024)   525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 7, 6, 1024)   263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 7, 6, 1024)   4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 7, 6, 1024)   4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 7, 6, 1024)   0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 7, 6, 1024)   0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 7, 6, 256)    262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 7, 6, 256)    1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 7, 6, 256)    0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 7, 6, 256)    590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 7, 6, 256)    1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 7, 6, 256)    0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 7, 6, 1024)   263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 7, 6, 1024)   4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 7, 6, 1024)   0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 7, 6, 1024)   0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 7, 6, 256)    262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 7, 6, 256)    1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 7, 6, 256)    0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 7, 6, 256)    590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 7, 6, 256)    1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 7, 6, 256)    0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 7, 6, 1024)   263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 7, 6, 1024)   4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 7, 6, 1024)   0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 7, 6, 1024)   0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 7, 6, 256)    262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 7, 6, 256)    1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 7, 6, 256)    0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 7, 6, 256)    590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 7, 6, 256)    1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 7, 6, 256)    0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 7, 6, 1024)   263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 7, 6, 1024)   4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 7, 6, 1024)   0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 7, 6, 1024)   0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 7, 6, 256)    262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 7, 6, 256)    1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 7, 6, 256)    0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 7, 6, 256)    590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 7, 6, 256)    1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 7, 6, 256)    0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 7, 6, 1024)   263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 7, 6, 1024)   4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 7, 6, 1024)   0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 7, 6, 1024)   0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 7, 6, 256)    262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 7, 6, 256)    1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 7, 6, 256)    0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 7, 6, 256)    590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 7, 6, 256)    1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 7, 6, 256)    0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 7, 6, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 7, 6, 1024)   4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 7, 6, 1024)   0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 7, 6, 1024)   0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 4, 3, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 4, 3, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 4, 3, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 4, 3, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 4, 3, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 4, 3, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 4, 3, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 4, 3, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 4, 3, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 4, 3, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 4, 3, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 4, 3, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 4, 3, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 4, 3, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 4, 3, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 4, 3, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 4, 3, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 4, 3, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 4, 3, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 4, 3, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 4, 3, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 4, 3, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 4, 3, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 4, 3, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 4, 3, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 4, 3, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 4, 3, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 4, 3, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 4, 3, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 4, 3, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 4, 3, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 4, 3, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 24576)        0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 200)          4915400     flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 20)           4020        dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 28,507,132\n",
      "Trainable params: 4,919,420\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53700de5",
   "metadata": {},
   "source": [
    "# Run the Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5c6c1268",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = trainX.reshape(240,112,92,3)\n",
    "testX = testX.reshape(160,112,92,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2c92846d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.compile(optimizer='adam',\n",
    "             loss ='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "43066ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "15/15 [==============================] - 9s 586ms/step - loss: 7.0180 - accuracy: 0.4875 - val_loss: 1.5382 - val_accuracy: 0.7563\n",
      "Epoch 2/20\n",
      "15/15 [==============================] - 8s 519ms/step - loss: 0.2959 - accuracy: 0.9250 - val_loss: 0.2988 - val_accuracy: 0.9375\n",
      "Epoch 3/20\n",
      "15/15 [==============================] - 8s 553ms/step - loss: 0.0376 - accuracy: 0.9875 - val_loss: 0.3552 - val_accuracy: 0.9250\n",
      "Epoch 4/20\n",
      "15/15 [==============================] - 8s 519ms/step - loss: 0.0062 - accuracy: 0.9958 - val_loss: 0.3330 - val_accuracy: 0.9438\n",
      "Epoch 5/20\n",
      "15/15 [==============================] - 8s 523ms/step - loss: 2.2444e-04 - accuracy: 1.0000 - val_loss: 0.2562 - val_accuracy: 0.9688\n",
      "Epoch 6/20\n",
      "15/15 [==============================] - 8s 529ms/step - loss: 8.8349e-05 - accuracy: 1.0000 - val_loss: 0.2440 - val_accuracy: 0.9688\n",
      "Epoch 7/20\n",
      "15/15 [==============================] - 8s 534ms/step - loss: 7.7398e-05 - accuracy: 1.0000 - val_loss: 0.2402 - val_accuracy: 0.9688\n",
      "Epoch 8/20\n",
      "15/15 [==============================] - 8s 526ms/step - loss: 6.6379e-05 - accuracy: 1.0000 - val_loss: 0.2386 - val_accuracy: 0.9688\n",
      "Epoch 9/20\n",
      "15/15 [==============================] - 8s 522ms/step - loss: 6.0449e-05 - accuracy: 1.0000 - val_loss: 0.2375 - val_accuracy: 0.9750\n",
      "Epoch 10/20\n",
      "15/15 [==============================] - 8s 523ms/step - loss: 5.3998e-05 - accuracy: 1.0000 - val_loss: 0.2364 - val_accuracy: 0.9750\n",
      "Epoch 11/20\n",
      "15/15 [==============================] - 8s 556ms/step - loss: 4.8187e-05 - accuracy: 1.0000 - val_loss: 0.2354 - val_accuracy: 0.9750\n",
      "Epoch 12/20\n",
      "15/15 [==============================] - 8s 527ms/step - loss: 4.3807e-05 - accuracy: 1.0000 - val_loss: 0.2347 - val_accuracy: 0.9750\n",
      "Epoch 13/20\n",
      "15/15 [==============================] - 8s 527ms/step - loss: 3.9690e-05 - accuracy: 1.0000 - val_loss: 0.2341 - val_accuracy: 0.9750\n",
      "Epoch 14/20\n",
      "15/15 [==============================] - 8s 540ms/step - loss: 3.6672e-05 - accuracy: 1.0000 - val_loss: 0.2333 - val_accuracy: 0.9750\n",
      "Epoch 15/20\n",
      "15/15 [==============================] - 8s 527ms/step - loss: 3.3943e-05 - accuracy: 1.0000 - val_loss: 0.2328 - val_accuracy: 0.9750\n",
      "Epoch 16/20\n",
      "15/15 [==============================] - 8s 527ms/step - loss: 3.1567e-05 - accuracy: 1.0000 - val_loss: 0.2322 - val_accuracy: 0.9750\n",
      "Epoch 17/20\n",
      "15/15 [==============================] - 8s 523ms/step - loss: 2.9510e-05 - accuracy: 1.0000 - val_loss: 0.2317 - val_accuracy: 0.9750\n",
      "Epoch 18/20\n",
      "15/15 [==============================] - 8s 556ms/step - loss: 2.7748e-05 - accuracy: 1.0000 - val_loss: 0.2312 - val_accuracy: 0.9812\n",
      "Epoch 19/20\n",
      "15/15 [==============================] - 8s 532ms/step - loss: 2.6321e-05 - accuracy: 1.0000 - val_loss: 0.2309 - val_accuracy: 0.9812\n",
      "Epoch 20/20\n",
      "15/15 [==============================] - 8s 524ms/step - loss: 2.4783e-05 - accuracy: 1.0000 - val_loss: 0.2304 - val_accuracy: 0.9812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f01c50fa350>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.fit(trainX, trainY, validation_data=(testX,testY), epochs=20, batch_size =16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ba8eb993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LR reduction on plateuing for pushing the accuracy further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c7e7948b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prediction = final_model.predict(testX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b4092690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 20)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4b088322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of misclassifications:  3\n"
     ]
    }
   ],
   "source": [
    "print('No of misclassifications: ',((final_prediction.argmax(axis=1))!= testY.argmax(axis=1)).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6c0855ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  4,  4,\n",
       "        4, 17,  4,  4,  4,  4,  5,  5,  5,  5,  5,  5,  5,  5,  6,  6,  6,\n",
       "        6,  6,  6,  6,  6,  7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,\n",
       "        8,  8,  8,  8,  9,  9,  9,  7,  9,  9,  9,  7, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12,\n",
       "       12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14,\n",
       "       14, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "       17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 19,\n",
       "       19, 19, 19, 19, 19, 19, 19])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prediction.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4b2c1ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  4,  4,\n",
       "        4,  4,  4,  4,  4,  4,  5,  5,  5,  5,  5,  5,  5,  5,  6,  6,  6,\n",
       "        6,  6,  6,  6,  6,  7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,\n",
       "        8,  8,  8,  8,  9,  9,  9,  9,  9,  9,  9,  9, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12,\n",
       "       12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14,\n",
       "       14, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "       17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 19,\n",
       "       19, 19, 19, 19, 19, 19, 19])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testY.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "42920d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LR reduction on plateuing for pushing the accuracy further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c929b37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
